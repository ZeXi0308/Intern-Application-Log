1. 讲一下你所构建或理解的 RAG (检索增强生成) 框架的端到端架构和你的设计思路

2. 在构建 RAG 系统时，针对关键组件（如文档解析、向量数据库、LLM），你是如何进行技术选型的？

3. 讲一下你另一段实习做的内容吧，你做了什么，具体是怎么实现的

4. 你是如何实现混合检索 (Hybrid Search)的？

5. prompt template你是怎么设计的

6. 你的系统是怎么处理用户上传的临时文档，并保证其与主知识库的数据隔离？

7. 你用了deepseek和Ollama是双通道得到结果还是仅使用了一个通道，为什么ollama一般在什么场景下使用呢

8. 系统如何支持对多文档源的查询，其底层是通过什么机制（如元数据 Metadata）来管理和溯源的？

9. 讲一下数据在整个 RAG 处理链路中的核心数据结构或格式。从接收用户请求，到检索、再到最终生成答案，数据对象是如何定义和变化的？

10.“长文档解析一百毫秒以内”的性能目标，我不理解这个指标，讲一下？(为了实现高吞吐和低延迟的文档处理)，用了哪些方法？(异步编程和任务图 (Task Graph / DAG))

11. 在任务图中，当存在并行分支时（例如，对多个文档块并行执行 Embedding），最终是如何将这些分支的结果合并的？实现机制是怎么样的。

12. 你的rerank是怎么做的，具体的排名策略是什么，(说了RRF的原理)

13. 你用了什么方法评估你这个系统的表现？你会关注哪些核心指标？怎么分离评估检索器 (Retriever)和生成器 (Generator)的性能？

14. 你对这个系统进行过优化吗，在何种情况下会考虑对 Embedding 模型或 LLM进行微调 (Fine-tuning)？
